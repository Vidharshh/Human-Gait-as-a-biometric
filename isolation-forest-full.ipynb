{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import IsolationForest\n\n# Load the CSV file\ndata = pd.read_csv('/kaggle/input/gait-analysis/gait_features_cnn_trained.csv')\n\n# Split the data into training and testing sets, while maintaining the ratio of labels in both sets\ntrain, test = train_test_split(data, test_size=0.2, stratify=data['label'])\n\n# Save the training and testing sets to CSV files\ntrain.to_csv('train.csv', index=False)\ntest.to_csv('test.csv', index=False)\n\ndf_anomalies = pd.read_csv('/kaggle/input/gait-analysis/gait_features_cnn_nottrained.csv')\ntrain, test = train_test_split(df_anomalies, test_size=0.2, stratify=df_anomalies['label'])\ntrain.to_csv('train1.csv', index=False)\ntest.to_csv('test1.csv', index=False)\n\n# Split features and labels for trained data\nX_trained = data.iloc[:, :-1]\ny_trained = pd.Series([1] * len(data)) # Set labels to 1 (trained)\n\n# Split features and labels for anomalies data\nX_anomalies = df_anomalies.iloc[:, :-1]\ny_anomalies = pd.Series([-1] * len(df_anomalies)) # Set labels to -1 (anomalies)\n\n# Concatenate the dataframes together\ndf_combined = pd.concat([X_trained, X_anomalies])\ny_combined = pd.concat([y_trained, y_anomalies], ignore_index=True)\n\n# Shuffle the rows of the combined dataframe\ndf_combined = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Scale the feature values\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(df_combined)\n\n# Train the Isolation Forest model\niforest = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)\niforest.fit(X_scaled, y_combined)\n\n# Load the new data to predict\ndf_new = pd.read_csv('test.csv')\n\n# Split features and labels\nX_new = df_new.iloc[:, :-1]\ny_new = df_new.iloc[:, -1]\n\n# Scale the feature values\nX_new_scaled = scaler.transform(X_new)\n\n# Predict the scores of the new data\ny_pred = iforest.score_samples(X_new_scaled)\n\n# Set a threshold for classifying instances as anomalies\nthreshold = -0.4\ny_pred_class = [1 if y < threshold else 0 for y in y_pred]\n\n\n# Evaluate the model on the test set\ny_test = df_new.iloc[:, -1]\ny_test[y_test != 1] = 0  # Set non-trained labels to -1\nprint(classification_report(y_test, y_pred_class))\n\n# Load the new data to predict\ndf_new = pd.read_csv('test1.csv')\n\n# Split features and labels\nX_new = df_new.iloc[:, :-1]\ny_new = df_new.iloc[:, -1]\n\n# Scale the feature values\nX_new_scaled = scaler.transform(X_new)\n\n# Predict the scores of the new data\ny_pred = iforest.score_samples(X_new_scaled)\n\n# Set a threshold for classifying instances as anomalies\nthreshold = -0.4\ny_pred_class = [1 if y < threshold else 0 for y in y_pred]\n\n\n# Evaluate the model on the test set\ny_test = df_new.iloc[:, -1]\ny_test[y_test != 1] = 0  # Set non-trained labels to -1\nprint(classification_report(y_test, y_pred_class))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-24T14:48:37.420530Z","iopub.execute_input":"2023-04-24T14:48:37.421992Z","iopub.status.idle":"2023-04-24T14:51:18.561900Z","shell.execute_reply.started":"2023-04-24T14:48:37.421920Z","shell.execute_reply":"2023-04-24T14:51:18.559941Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.96      0.98      2477\n           1       0.00      0.00      0.00        22\n\n    accuracy                           0.95      2499\n   macro avg       0.50      0.48      0.49      2499\nweighted avg       0.98      0.95      0.97      2499\n\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       220\n           1       0.00      0.00      0.00         0\n\n    accuracy                           1.00       220\n   macro avg       0.50      0.50      0.50       220\nweighted avg       1.00      1.00      1.00       220\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:88: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U scikit-learn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-29T14:36:58.484187Z","iopub.execute_input":"2023-04-29T14:36:58.485047Z","iopub.status.idle":"2023-04-29T14:37:03.058331Z","shell.execute_reply.started":"2023-04-29T14:36:58.485004Z","shell.execute_reply":"2023-04-29T14:37:03.057387Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/site-packages (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.23.5)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install xgboost","metadata":{"execution":{"iopub.status.busy":"2023-04-29T14:37:04.835411Z","iopub.execute_input":"2023-04-29T14:37:04.836171Z","iopub.status.idle":"2023-04-29T14:37:17.852688Z","shell.execute_reply.started":"2023-04-29T14:37:04.836130Z","shell.execute_reply":"2023-04-29T14:37:17.851747Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting xgboost\n  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/site-packages (from xgboost) (1.10.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from xgboost) (1.23.5)\nInstalling collected packages: xgboost\nSuccessfully installed xgboost-1.7.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"pip install opencv-python\n","metadata":{"execution":{"iopub.status.busy":"2023-04-29T14:37:17.854313Z","iopub.execute_input":"2023-04-29T14:37:17.854762Z","iopub.status.idle":"2023-04-29T14:37:26.595230Z","shell.execute_reply.started":"2023-04-29T14:37:17.854728Z","shell.execute_reply":"2023-04-29T14:37:26.594174Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting opencv-python\n  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/site-packages (from opencv-python) (1.23.5)\nInstalling collected packages: opencv-python\nSuccessfully installed opencv-python-4.7.0.72\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n# Define TPU strategy\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n\n    # Load data\n    df = pd.read_csv('/kaggle/input/gait-analysis/gait_features_cnn_trained.csv')\n    X = df.drop(['label'], axis=1).values\n    y = df['label'].values\n\n    # Encode the labels\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n\n    # Split data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Reshape data for use with VGG16\n    X_train = X_train.reshape(-1, 64, 64)\n    X_test = X_test.reshape(-1, 64, 64)\n    X_train = np.repeat(X_train[..., np.newaxis], 3, -1)\n    X_test = np.repeat(X_test[..., np.newaxis], 3, -1)\n\n    # Load VGG16 model and freeze convolutional layers\n    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n    vgg16.trainable = False\n\n    # Create a CNN model\n    model = Sequential()\n    model.add(vgg16)\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n\n    # Compile the model\n    optimizer = Adam(learning_rate=1e-4)\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    # Train the model\n    model.fit(X_train, y_train, epochs=250, validation_data=(X_test, y_test))\n\n    # Perform predictions using the model\n    y_pred = model.predict(X_test)\n    y_pred = np.argmax(y_pred, axis=1)\n\n    # Convert predicted labels back to original labels using label encoder\n    y_pred_labels = label_encoder.inverse_transform(y_pred)\n    \n    # Print the accuracy score\n    accuracy = accuracy_score(y_test, y_pred)\n    print('Test Accuracy:', accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T05:50:49.523451Z","iopub.execute_input":"2023-04-27T05:50:49.524131Z","iopub.status.idle":"2023-04-27T06:09:55.110569Z","shell.execute_reply.started":"2023-04-27T05:50:49.524095Z","shell.execute_reply":"2023-04-27T06:09:55.109239Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"D0427 05:51:21.662438735      14 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD0427 05:51:21.662470247      14 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD0427 05:51:21.662473625      14 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD0427 05:51:21.662476074      14 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD0427 05:51:21.662478354      14 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD0427 05:51:21.662480872      14 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD0427 05:51:21.662484157      14 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD0427 05:51:21.662486344      14 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD0427 05:51:21.662488619      14 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD0427 05:51:21.662490687      14 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD0427 05:51:21.662492734      14 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD0427 05:51:21.662494833      14 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD0427 05:51:21.662497067      14 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD0427 05:51:21.662499156      14 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI0427 05:51:21.662664980      14 ev_epoll1_linux.cc:122]               grpc epoll fd: 62\nD0427 05:51:21.669054378      14 ev_posix.cc:144]                      Using polling engine: epoll1\nD0427 05:51:21.669075326      14 dns_resolver_ares.cc:822]             Using ares dns resolver\nD0427 05:51:21.669487499      14 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0427 05:51:21.669500401      14 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0427 05:51:21.669503537      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0427 05:51:21.669506341      14 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0427 05:51:21.669509104      14 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0427 05:51:21.669511782      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD0427 05:51:21.669518168      14 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0427 05:51:21.669531427      14 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0427 05:51:21.669555383      14 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0427 05:51:21.669568568      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0427 05:51:21.669571468      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0427 05:51:21.669574141      14 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0427 05:51:21.669579813      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD0427 05:51:21.669583068      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0427 05:51:21.669586165      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0427 05:51:21.669590031      14 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI0427 05:51:21.671754865      14 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI0427 05:51:21.698131352     262 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0427 05:51:21.724898856      14 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2023-04-27T05:51:21.724882731+00:00\", grpc_status:2}\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 1s 0us/step\nEpoch 1/250\n","output_type":"stream"},{"name":"stderr","text":"2023-04-27 05:52:07.041250: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-04-27 05:52:07.165283: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"313/313 [==============================] - ETA: 0s - loss: 4.9678 - accuracy: 0.0120","output_type":"stream"},{"name":"stderr","text":"2023-04-27 05:52:23.064903: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-04-27 05:52:23.172822: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"313/313 [==============================] - 30s 69ms/step - loss: 4.9678 - accuracy: 0.0120 - val_loss: 4.6727 - val_accuracy: 0.0212\nEpoch 2/250\n313/313 [==============================] - 4s 13ms/step - loss: 4.6729 - accuracy: 0.0244 - val_loss: 4.6076 - val_accuracy: 0.0420\nEpoch 3/250\n313/313 [==============================] - 4s 13ms/step - loss: 4.5903 - accuracy: 0.0360 - val_loss: 4.5070 - val_accuracy: 0.0552\nEpoch 4/250\n313/313 [==============================] - 4s 13ms/step - loss: 4.4969 - accuracy: 0.0489 - val_loss: 4.3828 - val_accuracy: 0.0768\nEpoch 5/250\n313/313 [==============================] - 4s 13ms/step - loss: 4.3935 - accuracy: 0.0565 - val_loss: 4.2738 - val_accuracy: 0.0932\nEpoch 6/250\n313/313 [==============================] - 4s 14ms/step - loss: 4.2867 - accuracy: 0.0667 - val_loss: 4.1664 - val_accuracy: 0.1164\nEpoch 7/250\n313/313 [==============================] - 4s 13ms/step - loss: 4.1965 - accuracy: 0.0819 - val_loss: 4.0629 - val_accuracy: 0.1261\nEpoch 8/250\n313/313 [==============================] - 4s 13ms/step - loss: 4.0980 - accuracy: 0.1002 - val_loss: 3.9769 - val_accuracy: 0.1433\nEpoch 9/250\n313/313 [==============================] - 4s 13ms/step - loss: 4.0215 - accuracy: 0.1048 - val_loss: 3.9019 - val_accuracy: 0.1557\nEpoch 10/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.9393 - accuracy: 0.1201 - val_loss: 3.8242 - val_accuracy: 0.1661\nEpoch 11/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.8725 - accuracy: 0.1265 - val_loss: 3.7415 - val_accuracy: 0.1849\nEpoch 12/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.7919 - accuracy: 0.1427 - val_loss: 3.6766 - val_accuracy: 0.1965\nEpoch 13/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.7249 - accuracy: 0.1512 - val_loss: 3.5980 - val_accuracy: 0.2089\nEpoch 14/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.6531 - accuracy: 0.1633 - val_loss: 3.5463 - val_accuracy: 0.2133\nEpoch 15/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.5944 - accuracy: 0.1685 - val_loss: 3.5024 - val_accuracy: 0.2221\nEpoch 16/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.5343 - accuracy: 0.1845 - val_loss: 3.4248 - val_accuracy: 0.2433\nEpoch 17/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.4830 - accuracy: 0.1885 - val_loss: 3.3838 - val_accuracy: 0.2533\nEpoch 18/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.4251 - accuracy: 0.2042 - val_loss: 3.3329 - val_accuracy: 0.2681\nEpoch 19/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.3840 - accuracy: 0.2061 - val_loss: 3.2843 - val_accuracy: 0.2721\nEpoch 20/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.3357 - accuracy: 0.2173 - val_loss: 3.2262 - val_accuracy: 0.2809\nEpoch 21/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.2703 - accuracy: 0.2349 - val_loss: 3.1896 - val_accuracy: 0.2921\nEpoch 22/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.2248 - accuracy: 0.2367 - val_loss: 3.1419 - val_accuracy: 0.3045\nEpoch 23/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.1769 - accuracy: 0.2518 - val_loss: 3.0869 - val_accuracy: 0.3073\nEpoch 24/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.1542 - accuracy: 0.2536 - val_loss: 3.0638 - val_accuracy: 0.3245\nEpoch 25/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.0994 - accuracy: 0.2611 - val_loss: 3.0242 - val_accuracy: 0.3245\nEpoch 26/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.0566 - accuracy: 0.2717 - val_loss: 2.9870 - val_accuracy: 0.3385\nEpoch 27/250\n313/313 [==============================] - 4s 13ms/step - loss: 3.0212 - accuracy: 0.2771 - val_loss: 2.9626 - val_accuracy: 0.3461\nEpoch 28/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.9813 - accuracy: 0.2776 - val_loss: 2.9156 - val_accuracy: 0.3537\nEpoch 29/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.9414 - accuracy: 0.2894 - val_loss: 2.8934 - val_accuracy: 0.3557\nEpoch 30/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.9132 - accuracy: 0.3032 - val_loss: 2.8468 - val_accuracy: 0.3609\nEpoch 31/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.8903 - accuracy: 0.2965 - val_loss: 2.8154 - val_accuracy: 0.3697\nEpoch 32/250\n313/313 [==============================] - 4s 14ms/step - loss: 2.8517 - accuracy: 0.3041 - val_loss: 2.8000 - val_accuracy: 0.3717\nEpoch 33/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.8201 - accuracy: 0.3148 - val_loss: 2.7712 - val_accuracy: 0.3794\nEpoch 34/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.7825 - accuracy: 0.3227 - val_loss: 2.7402 - val_accuracy: 0.3926\nEpoch 35/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.7521 - accuracy: 0.3305 - val_loss: 2.7137 - val_accuracy: 0.3910\nEpoch 36/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.7095 - accuracy: 0.3301 - val_loss: 2.7003 - val_accuracy: 0.3858\nEpoch 37/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.6913 - accuracy: 0.3390 - val_loss: 2.6564 - val_accuracy: 0.3970\nEpoch 38/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.6547 - accuracy: 0.3549 - val_loss: 2.6244 - val_accuracy: 0.4014\nEpoch 39/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.6393 - accuracy: 0.3538 - val_loss: 2.6111 - val_accuracy: 0.4058\nEpoch 40/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.5858 - accuracy: 0.3682 - val_loss: 2.5885 - val_accuracy: 0.4090\nEpoch 41/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.5738 - accuracy: 0.3688 - val_loss: 2.5714 - val_accuracy: 0.4110\nEpoch 42/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.5482 - accuracy: 0.3710 - val_loss: 2.5436 - val_accuracy: 0.4242\nEpoch 43/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.5364 - accuracy: 0.3755 - val_loss: 2.5253 - val_accuracy: 0.4278\nEpoch 44/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.5031 - accuracy: 0.3768 - val_loss: 2.5103 - val_accuracy: 0.4286\nEpoch 45/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.4580 - accuracy: 0.3871 - val_loss: 2.4785 - val_accuracy: 0.4358\nEpoch 46/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.4472 - accuracy: 0.3893 - val_loss: 2.4604 - val_accuracy: 0.4426\nEpoch 47/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.4263 - accuracy: 0.3968 - val_loss: 2.4386 - val_accuracy: 0.4398\nEpoch 48/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.4083 - accuracy: 0.3990 - val_loss: 2.4246 - val_accuracy: 0.4446\nEpoch 49/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.3753 - accuracy: 0.4101 - val_loss: 2.3959 - val_accuracy: 0.4486\nEpoch 50/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.3576 - accuracy: 0.4141 - val_loss: 2.3926 - val_accuracy: 0.4674\nEpoch 51/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.3340 - accuracy: 0.4185 - val_loss: 2.3791 - val_accuracy: 0.4578\nEpoch 52/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.3240 - accuracy: 0.4199 - val_loss: 2.3557 - val_accuracy: 0.4602\nEpoch 53/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.3084 - accuracy: 0.4241 - val_loss: 2.3460 - val_accuracy: 0.4630\nEpoch 54/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.2874 - accuracy: 0.4276 - val_loss: 2.3333 - val_accuracy: 0.4710\nEpoch 55/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.2541 - accuracy: 0.4300 - val_loss: 2.3192 - val_accuracy: 0.4750\nEpoch 56/250\n313/313 [==============================] - 5s 15ms/step - loss: 2.2598 - accuracy: 0.4309 - val_loss: 2.2882 - val_accuracy: 0.4810\nEpoch 57/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.2416 - accuracy: 0.4353 - val_loss: 2.2881 - val_accuracy: 0.4722\nEpoch 58/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.2062 - accuracy: 0.4440 - val_loss: 2.2580 - val_accuracy: 0.4834\nEpoch 59/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.1849 - accuracy: 0.4519 - val_loss: 2.2507 - val_accuracy: 0.4814\nEpoch 60/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.1629 - accuracy: 0.4564 - val_loss: 2.2595 - val_accuracy: 0.4794\nEpoch 61/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.1609 - accuracy: 0.4542 - val_loss: 2.2337 - val_accuracy: 0.4898\nEpoch 62/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.1320 - accuracy: 0.4615 - val_loss: 2.2218 - val_accuracy: 0.4794\nEpoch 63/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.1117 - accuracy: 0.4688 - val_loss: 2.2064 - val_accuracy: 0.4926\nEpoch 64/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.1101 - accuracy: 0.4617 - val_loss: 2.1836 - val_accuracy: 0.4986\nEpoch 65/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.0922 - accuracy: 0.4706 - val_loss: 2.1776 - val_accuracy: 0.4894\nEpoch 66/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.0701 - accuracy: 0.4716 - val_loss: 2.1497 - val_accuracy: 0.4998\nEpoch 67/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.0630 - accuracy: 0.4803 - val_loss: 2.1445 - val_accuracy: 0.4906\nEpoch 68/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.0428 - accuracy: 0.4788 - val_loss: 2.1379 - val_accuracy: 0.4982\nEpoch 69/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.0214 - accuracy: 0.4815 - val_loss: 2.1326 - val_accuracy: 0.5030\nEpoch 70/250\n313/313 [==============================] - 4s 13ms/step - loss: 2.0099 - accuracy: 0.4901 - val_loss: 2.1164 - val_accuracy: 0.5030\nEpoch 71/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.9958 - accuracy: 0.4858 - val_loss: 2.1070 - val_accuracy: 0.5110\nEpoch 72/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.9704 - accuracy: 0.4938 - val_loss: 2.0889 - val_accuracy: 0.5058\nEpoch 73/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.9763 - accuracy: 0.4999 - val_loss: 2.0732 - val_accuracy: 0.5154\nEpoch 74/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.9588 - accuracy: 0.5021 - val_loss: 2.0549 - val_accuracy: 0.5122\nEpoch 75/250\n313/313 [==============================] - 4s 14ms/step - loss: 1.9512 - accuracy: 0.5010 - val_loss: 2.0571 - val_accuracy: 0.5138\nEpoch 76/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.9225 - accuracy: 0.5059 - val_loss: 2.0480 - val_accuracy: 0.5150\nEpoch 77/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.9140 - accuracy: 0.5080 - val_loss: 2.0384 - val_accuracy: 0.5198\nEpoch 78/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.9130 - accuracy: 0.5096 - val_loss: 2.0444 - val_accuracy: 0.5230\nEpoch 79/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.8874 - accuracy: 0.5110 - val_loss: 2.0265 - val_accuracy: 0.5202\nEpoch 80/250\n313/313 [==============================] - 4s 14ms/step - loss: 1.8605 - accuracy: 0.5199 - val_loss: 2.0094 - val_accuracy: 0.5262\nEpoch 81/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.8507 - accuracy: 0.5239 - val_loss: 2.0034 - val_accuracy: 0.5314\nEpoch 82/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.8495 - accuracy: 0.5248 - val_loss: 1.9899 - val_accuracy: 0.5266\nEpoch 83/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.8324 - accuracy: 0.5283 - val_loss: 1.9991 - val_accuracy: 0.5346\nEpoch 84/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.8356 - accuracy: 0.5282 - val_loss: 1.9853 - val_accuracy: 0.5282\nEpoch 85/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.8002 - accuracy: 0.5367 - val_loss: 1.9723 - val_accuracy: 0.5342\nEpoch 86/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.8068 - accuracy: 0.5275 - val_loss: 1.9458 - val_accuracy: 0.5334\nEpoch 87/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.8012 - accuracy: 0.5337 - val_loss: 1.9483 - val_accuracy: 0.5446\nEpoch 88/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.7623 - accuracy: 0.5358 - val_loss: 1.9373 - val_accuracy: 0.5422\nEpoch 89/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.7679 - accuracy: 0.5399 - val_loss: 1.9345 - val_accuracy: 0.5410\nEpoch 90/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.7544 - accuracy: 0.5452 - val_loss: 1.9199 - val_accuracy: 0.5494\nEpoch 91/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.7533 - accuracy: 0.5478 - val_loss: 1.9183 - val_accuracy: 0.5414\nEpoch 92/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.7347 - accuracy: 0.5500 - val_loss: 1.9116 - val_accuracy: 0.5474\nEpoch 93/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.7279 - accuracy: 0.5475 - val_loss: 1.8984 - val_accuracy: 0.5410\nEpoch 94/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.7170 - accuracy: 0.5541 - val_loss: 1.8986 - val_accuracy: 0.5518\nEpoch 95/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.6905 - accuracy: 0.5561 - val_loss: 1.8951 - val_accuracy: 0.5494\nEpoch 96/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.6867 - accuracy: 0.5620 - val_loss: 1.8657 - val_accuracy: 0.5530\nEpoch 97/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.6786 - accuracy: 0.5691 - val_loss: 1.8761 - val_accuracy: 0.5546\nEpoch 98/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.6753 - accuracy: 0.5595 - val_loss: 1.8696 - val_accuracy: 0.5550\nEpoch 99/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.6627 - accuracy: 0.5684 - val_loss: 1.8521 - val_accuracy: 0.5542\nEpoch 100/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.6534 - accuracy: 0.5670 - val_loss: 1.8399 - val_accuracy: 0.5662\nEpoch 101/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.6324 - accuracy: 0.5683 - val_loss: 1.8390 - val_accuracy: 0.5538\nEpoch 102/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.6487 - accuracy: 0.5706 - val_loss: 1.8503 - val_accuracy: 0.5598\nEpoch 103/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.6188 - accuracy: 0.5801 - val_loss: 1.8390 - val_accuracy: 0.5554\nEpoch 104/250\n313/313 [==============================] - 4s 14ms/step - loss: 1.6235 - accuracy: 0.5777 - val_loss: 1.8184 - val_accuracy: 0.5710\nEpoch 105/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.6125 - accuracy: 0.5720 - val_loss: 1.8152 - val_accuracy: 0.5602\nEpoch 106/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.6046 - accuracy: 0.5789 - val_loss: 1.8237 - val_accuracy: 0.5658\nEpoch 107/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.5852 - accuracy: 0.5874 - val_loss: 1.8109 - val_accuracy: 0.5662\nEpoch 108/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.5820 - accuracy: 0.5840 - val_loss: 1.8101 - val_accuracy: 0.5674\nEpoch 109/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.5675 - accuracy: 0.5861 - val_loss: 1.7947 - val_accuracy: 0.5710\nEpoch 110/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.5610 - accuracy: 0.5855 - val_loss: 1.7835 - val_accuracy: 0.5726\nEpoch 111/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.5627 - accuracy: 0.5893 - val_loss: 1.7868 - val_accuracy: 0.5714\nEpoch 112/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.5381 - accuracy: 0.6009 - val_loss: 1.7974 - val_accuracy: 0.5606\nEpoch 113/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.5390 - accuracy: 0.5942 - val_loss: 1.7732 - val_accuracy: 0.5714\nEpoch 114/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.5230 - accuracy: 0.6000 - val_loss: 1.7700 - val_accuracy: 0.5750\nEpoch 115/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.5361 - accuracy: 0.5883 - val_loss: 1.7718 - val_accuracy: 0.5778\nEpoch 116/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.5142 - accuracy: 0.5953 - val_loss: 1.7623 - val_accuracy: 0.5818\nEpoch 117/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4812 - accuracy: 0.6087 - val_loss: 1.7478 - val_accuracy: 0.5774\nEpoch 118/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4895 - accuracy: 0.6067 - val_loss: 1.7520 - val_accuracy: 0.5786\nEpoch 119/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4781 - accuracy: 0.6016 - val_loss: 1.7538 - val_accuracy: 0.5822\nEpoch 120/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4761 - accuracy: 0.6042 - val_loss: 1.7263 - val_accuracy: 0.5778\nEpoch 121/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4767 - accuracy: 0.6070 - val_loss: 1.7416 - val_accuracy: 0.5762\nEpoch 122/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4750 - accuracy: 0.6024 - val_loss: 1.7315 - val_accuracy: 0.5870\nEpoch 123/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4536 - accuracy: 0.6143 - val_loss: 1.7259 - val_accuracy: 0.5822\nEpoch 124/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4436 - accuracy: 0.6140 - val_loss: 1.7244 - val_accuracy: 0.5810\nEpoch 125/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4331 - accuracy: 0.6214 - val_loss: 1.7158 - val_accuracy: 0.5810\nEpoch 126/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4236 - accuracy: 0.6186 - val_loss: 1.7047 - val_accuracy: 0.5858\nEpoch 127/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4248 - accuracy: 0.6230 - val_loss: 1.7066 - val_accuracy: 0.5886\nEpoch 128/250\n313/313 [==============================] - 5s 15ms/step - loss: 1.4239 - accuracy: 0.6174 - val_loss: 1.6952 - val_accuracy: 0.5950\nEpoch 129/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4184 - accuracy: 0.6227 - val_loss: 1.7134 - val_accuracy: 0.5830\nEpoch 130/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4113 - accuracy: 0.6186 - val_loss: 1.6862 - val_accuracy: 0.5934\nEpoch 131/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.4083 - accuracy: 0.6279 - val_loss: 1.6896 - val_accuracy: 0.5910\nEpoch 132/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3893 - accuracy: 0.6329 - val_loss: 1.6874 - val_accuracy: 0.5850\nEpoch 133/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3741 - accuracy: 0.6358 - val_loss: 1.6782 - val_accuracy: 0.5958\nEpoch 134/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3769 - accuracy: 0.6226 - val_loss: 1.6688 - val_accuracy: 0.5914\nEpoch 135/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3810 - accuracy: 0.6338 - val_loss: 1.6659 - val_accuracy: 0.5990\nEpoch 136/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3698 - accuracy: 0.6321 - val_loss: 1.6692 - val_accuracy: 0.5934\nEpoch 137/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3492 - accuracy: 0.6374 - val_loss: 1.6736 - val_accuracy: 0.5906\nEpoch 138/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3503 - accuracy: 0.6337 - val_loss: 1.6556 - val_accuracy: 0.5930\nEpoch 139/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3499 - accuracy: 0.6391 - val_loss: 1.6617 - val_accuracy: 0.5938\nEpoch 140/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3220 - accuracy: 0.6450 - val_loss: 1.6516 - val_accuracy: 0.6058\nEpoch 141/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3306 - accuracy: 0.6435 - val_loss: 1.6601 - val_accuracy: 0.5926\nEpoch 142/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3199 - accuracy: 0.6471 - val_loss: 1.6457 - val_accuracy: 0.5990\nEpoch 143/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3109 - accuracy: 0.6473 - val_loss: 1.6382 - val_accuracy: 0.5962\nEpoch 144/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3041 - accuracy: 0.6500 - val_loss: 1.6311 - val_accuracy: 0.6062\nEpoch 145/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.3068 - accuracy: 0.6458 - val_loss: 1.6430 - val_accuracy: 0.5986\nEpoch 146/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2835 - accuracy: 0.6532 - val_loss: 1.6296 - val_accuracy: 0.6022\nEpoch 147/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2897 - accuracy: 0.6512 - val_loss: 1.6297 - val_accuracy: 0.6078\nEpoch 148/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2919 - accuracy: 0.6551 - val_loss: 1.6282 - val_accuracy: 0.6026\nEpoch 149/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2865 - accuracy: 0.6551 - val_loss: 1.6298 - val_accuracy: 0.6030\nEpoch 150/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2715 - accuracy: 0.6556 - val_loss: 1.6275 - val_accuracy: 0.5986\nEpoch 151/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2673 - accuracy: 0.6570 - val_loss: 1.6235 - val_accuracy: 0.6018\nEpoch 152/250\n313/313 [==============================] - 5s 15ms/step - loss: 1.2551 - accuracy: 0.6609 - val_loss: 1.6198 - val_accuracy: 0.6066\nEpoch 153/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2633 - accuracy: 0.6536 - val_loss: 1.6379 - val_accuracy: 0.5966\nEpoch 154/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2489 - accuracy: 0.6617 - val_loss: 1.6134 - val_accuracy: 0.6026\nEpoch 155/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2430 - accuracy: 0.6625 - val_loss: 1.6156 - val_accuracy: 0.6058\nEpoch 156/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2426 - accuracy: 0.6594 - val_loss: 1.6054 - val_accuracy: 0.6006\nEpoch 157/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2438 - accuracy: 0.6624 - val_loss: 1.5965 - val_accuracy: 0.6106\nEpoch 158/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2279 - accuracy: 0.6658 - val_loss: 1.6027 - val_accuracy: 0.6138\nEpoch 159/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2239 - accuracy: 0.6672 - val_loss: 1.5957 - val_accuracy: 0.6114\nEpoch 160/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2131 - accuracy: 0.6692 - val_loss: 1.5951 - val_accuracy: 0.6066\nEpoch 161/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2130 - accuracy: 0.6665 - val_loss: 1.5837 - val_accuracy: 0.6130\nEpoch 162/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1997 - accuracy: 0.6730 - val_loss: 1.5917 - val_accuracy: 0.6018\nEpoch 163/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.2069 - accuracy: 0.6639 - val_loss: 1.5987 - val_accuracy: 0.6098\nEpoch 164/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1824 - accuracy: 0.6728 - val_loss: 1.5844 - val_accuracy: 0.6078\nEpoch 165/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1826 - accuracy: 0.6758 - val_loss: 1.5786 - val_accuracy: 0.6146\nEpoch 166/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1801 - accuracy: 0.6710 - val_loss: 1.5702 - val_accuracy: 0.6142\nEpoch 167/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1744 - accuracy: 0.6774 - val_loss: 1.5745 - val_accuracy: 0.6146\nEpoch 168/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1828 - accuracy: 0.6777 - val_loss: 1.5774 - val_accuracy: 0.6082\nEpoch 169/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1747 - accuracy: 0.6786 - val_loss: 1.5802 - val_accuracy: 0.6130\nEpoch 170/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1619 - accuracy: 0.6780 - val_loss: 1.5620 - val_accuracy: 0.6158\nEpoch 171/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1582 - accuracy: 0.6851 - val_loss: 1.5569 - val_accuracy: 0.6158\nEpoch 172/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1571 - accuracy: 0.6822 - val_loss: 1.5666 - val_accuracy: 0.6186\nEpoch 173/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1571 - accuracy: 0.6798 - val_loss: 1.5558 - val_accuracy: 0.6146\nEpoch 174/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1365 - accuracy: 0.6900 - val_loss: 1.5696 - val_accuracy: 0.6174\nEpoch 175/250\n313/313 [==============================] - 4s 14ms/step - loss: 1.1288 - accuracy: 0.6864 - val_loss: 1.5546 - val_accuracy: 0.6170\nEpoch 176/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1531 - accuracy: 0.6851 - val_loss: 1.5541 - val_accuracy: 0.6186\nEpoch 177/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1201 - accuracy: 0.6879 - val_loss: 1.5422 - val_accuracy: 0.6242\nEpoch 178/250\n313/313 [==============================] - 4s 14ms/step - loss: 1.1305 - accuracy: 0.6919 - val_loss: 1.5493 - val_accuracy: 0.6190\nEpoch 179/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1168 - accuracy: 0.6926 - val_loss: 1.5461 - val_accuracy: 0.6202\nEpoch 180/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1227 - accuracy: 0.6906 - val_loss: 1.5473 - val_accuracy: 0.6126\nEpoch 181/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1140 - accuracy: 0.6928 - val_loss: 1.5498 - val_accuracy: 0.6222\nEpoch 182/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1022 - accuracy: 0.6996 - val_loss: 1.5398 - val_accuracy: 0.6162\nEpoch 183/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0992 - accuracy: 0.6978 - val_loss: 1.5329 - val_accuracy: 0.6267\nEpoch 184/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.1055 - accuracy: 0.6933 - val_loss: 1.5525 - val_accuracy: 0.6182\nEpoch 185/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0853 - accuracy: 0.7002 - val_loss: 1.5457 - val_accuracy: 0.6190\nEpoch 186/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0850 - accuracy: 0.7029 - val_loss: 1.5330 - val_accuracy: 0.6158\nEpoch 187/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0765 - accuracy: 0.6986 - val_loss: 1.5439 - val_accuracy: 0.6146\nEpoch 188/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0701 - accuracy: 0.7032 - val_loss: 1.5366 - val_accuracy: 0.6226\nEpoch 189/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0650 - accuracy: 0.7089 - val_loss: 1.5247 - val_accuracy: 0.6259\nEpoch 190/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0673 - accuracy: 0.6977 - val_loss: 1.5235 - val_accuracy: 0.6182\nEpoch 191/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0819 - accuracy: 0.6988 - val_loss: 1.5194 - val_accuracy: 0.6311\nEpoch 192/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0567 - accuracy: 0.7051 - val_loss: 1.5143 - val_accuracy: 0.6291\nEpoch 193/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0484 - accuracy: 0.7066 - val_loss: 1.5273 - val_accuracy: 0.6255\nEpoch 194/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0566 - accuracy: 0.7099 - val_loss: 1.5319 - val_accuracy: 0.6166\nEpoch 195/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0425 - accuracy: 0.7087 - val_loss: 1.5298 - val_accuracy: 0.6202\nEpoch 196/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0482 - accuracy: 0.7077 - val_loss: 1.5138 - val_accuracy: 0.6311\nEpoch 197/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0360 - accuracy: 0.7175 - val_loss: 1.5120 - val_accuracy: 0.6218\nEpoch 198/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0371 - accuracy: 0.7131 - val_loss: 1.5060 - val_accuracy: 0.6299\nEpoch 199/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0243 - accuracy: 0.7176 - val_loss: 1.5114 - val_accuracy: 0.6315\nEpoch 200/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0241 - accuracy: 0.7103 - val_loss: 1.5024 - val_accuracy: 0.6343\nEpoch 201/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0214 - accuracy: 0.7136 - val_loss: 1.5072 - val_accuracy: 0.6263\nEpoch 202/250\n313/313 [==============================] - 5s 14ms/step - loss: 1.0098 - accuracy: 0.7203 - val_loss: 1.5039 - val_accuracy: 0.6251\nEpoch 203/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0219 - accuracy: 0.7166 - val_loss: 1.5023 - val_accuracy: 0.6299\nEpoch 204/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0253 - accuracy: 0.7153 - val_loss: 1.4980 - val_accuracy: 0.6267\nEpoch 205/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9966 - accuracy: 0.7249 - val_loss: 1.4974 - val_accuracy: 0.6307\nEpoch 206/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0141 - accuracy: 0.7152 - val_loss: 1.5000 - val_accuracy: 0.6267\nEpoch 207/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9901 - accuracy: 0.7246 - val_loss: 1.5077 - val_accuracy: 0.6255\nEpoch 208/250\n313/313 [==============================] - 4s 13ms/step - loss: 1.0067 - accuracy: 0.7161 - val_loss: 1.4864 - val_accuracy: 0.6307\nEpoch 209/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9885 - accuracy: 0.7222 - val_loss: 1.4936 - val_accuracy: 0.6355\nEpoch 210/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9926 - accuracy: 0.7183 - val_loss: 1.4868 - val_accuracy: 0.6331\nEpoch 211/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9805 - accuracy: 0.7282 - val_loss: 1.5053 - val_accuracy: 0.6343\nEpoch 212/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9861 - accuracy: 0.7253 - val_loss: 1.5025 - val_accuracy: 0.6375\nEpoch 213/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9695 - accuracy: 0.7276 - val_loss: 1.4871 - val_accuracy: 0.6331\nEpoch 214/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9598 - accuracy: 0.7295 - val_loss: 1.4879 - val_accuracy: 0.6395\nEpoch 215/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9774 - accuracy: 0.7269 - val_loss: 1.4889 - val_accuracy: 0.6395\nEpoch 216/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9663 - accuracy: 0.7291 - val_loss: 1.4908 - val_accuracy: 0.6327\nEpoch 217/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9500 - accuracy: 0.7365 - val_loss: 1.4904 - val_accuracy: 0.6311\nEpoch 218/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9470 - accuracy: 0.7343 - val_loss: 1.4868 - val_accuracy: 0.6335\nEpoch 219/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9462 - accuracy: 0.7325 - val_loss: 1.4802 - val_accuracy: 0.6339\nEpoch 220/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9544 - accuracy: 0.7295 - val_loss: 1.4707 - val_accuracy: 0.6355\nEpoch 221/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9483 - accuracy: 0.7314 - val_loss: 1.4783 - val_accuracy: 0.6339\nEpoch 222/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9452 - accuracy: 0.7327 - val_loss: 1.4606 - val_accuracy: 0.6419\nEpoch 223/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9466 - accuracy: 0.7329 - val_loss: 1.4705 - val_accuracy: 0.6351\nEpoch 224/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9436 - accuracy: 0.7355 - val_loss: 1.4757 - val_accuracy: 0.6391\nEpoch 225/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9137 - accuracy: 0.7438 - val_loss: 1.4689 - val_accuracy: 0.6351\nEpoch 226/250\n313/313 [==============================] - 5s 15ms/step - loss: 0.9192 - accuracy: 0.7434 - val_loss: 1.4714 - val_accuracy: 0.6339\nEpoch 227/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9305 - accuracy: 0.7356 - val_loss: 1.4726 - val_accuracy: 0.6347\nEpoch 228/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9224 - accuracy: 0.7388 - val_loss: 1.4714 - val_accuracy: 0.6387\nEpoch 229/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9275 - accuracy: 0.7385 - val_loss: 1.4760 - val_accuracy: 0.6311\nEpoch 230/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9277 - accuracy: 0.7374 - val_loss: 1.4723 - val_accuracy: 0.6335\nEpoch 231/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9066 - accuracy: 0.7406 - val_loss: 1.4817 - val_accuracy: 0.6319\nEpoch 232/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9057 - accuracy: 0.7460 - val_loss: 1.4611 - val_accuracy: 0.6299\nEpoch 233/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.9243 - accuracy: 0.7416 - val_loss: 1.4714 - val_accuracy: 0.6383\nEpoch 234/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8820 - accuracy: 0.7545 - val_loss: 1.4773 - val_accuracy: 0.6303\nEpoch 235/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8999 - accuracy: 0.7430 - val_loss: 1.4637 - val_accuracy: 0.6303\nEpoch 236/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8951 - accuracy: 0.7482 - val_loss: 1.4752 - val_accuracy: 0.6311\nEpoch 237/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8836 - accuracy: 0.7508 - val_loss: 1.4654 - val_accuracy: 0.6371\nEpoch 238/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8893 - accuracy: 0.7451 - val_loss: 1.4545 - val_accuracy: 0.6303\nEpoch 239/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8893 - accuracy: 0.7431 - val_loss: 1.4624 - val_accuracy: 0.6395\nEpoch 240/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8863 - accuracy: 0.7471 - val_loss: 1.4590 - val_accuracy: 0.6427\nEpoch 241/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8721 - accuracy: 0.7528 - val_loss: 1.4573 - val_accuracy: 0.6407\nEpoch 242/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8829 - accuracy: 0.7497 - val_loss: 1.4575 - val_accuracy: 0.6411\nEpoch 243/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8676 - accuracy: 0.7552 - val_loss: 1.4665 - val_accuracy: 0.6383\nEpoch 244/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8667 - accuracy: 0.7527 - val_loss: 1.4598 - val_accuracy: 0.6423\nEpoch 245/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8634 - accuracy: 0.7536 - val_loss: 1.4613 - val_accuracy: 0.6387\nEpoch 246/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8613 - accuracy: 0.7551 - val_loss: 1.4761 - val_accuracy: 0.6331\nEpoch 247/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8680 - accuracy: 0.7572 - val_loss: 1.4681 - val_accuracy: 0.6419\nEpoch 248/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8693 - accuracy: 0.7520 - val_loss: 1.4636 - val_accuracy: 0.6395\nEpoch 249/250\n313/313 [==============================] - 4s 13ms/step - loss: 0.8530 - accuracy: 0.7575 - val_loss: 1.4511 - val_accuracy: 0.6367\nEpoch 250/250\n313/313 [==============================] - 4s 14ms/step - loss: 0.8573 - accuracy: 0.7583 - val_loss: 1.4682 - val_accuracy: 0.6375\n","output_type":"stream"},{"name":"stderr","text":"2023-04-27 06:09:43.867724: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-04-27 06:09:43.955627: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"79/79 [==============================] - 12s 75ms/step\nTest Accuracy: 0.6374549819927972\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nimport xgboost as xgb\n\n# Define TPU strategy\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n\n    # Load data\n    df = pd.read_csv('/kaggle/input/gait-analysis/gait_features_cnn_trained.csv')\n    X = df.drop(['label'], axis=1).values\n    y = df['label'].values\n\n    # Encode the labels\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Reshape data for use with ResNet50\n    X_train = X_train.reshape(-1, 64, 64)\n    X_test = X_test.reshape(-1, 64, 64)\n    X_train = np.repeat(X_train[..., np.newaxis], 3, -1)\n    X_test = np.repeat(X_test[..., np.newaxis], 3, -1)\n\n    # Load ResNet50 model and freeze convolutional layers\n    resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n    resnet50.trainable = False\n\n    # Create a CNN model\n    model = Sequential()\n    model.add(resnet50)\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.45))\n    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n\n    # Compile the model\n    optimizer = Adam(learning_rate=0.0001)\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    # Train the CNN model\n    model.fit(X_train, y_train, epochs=250, validation_data=(X_test, y_test))\n\n    # Perform predictions using the CNN model\n    cnn_y_pred = model.predict(X_test)\n\n    # Train an XGBoost model\n    xgb_model = xgb.XGBClassifier(objective='multi:softmax')\n    xgb_model.fit(X_train.reshape(-1, 4096), y_train)\n    \n    # Perform predictions using the XGBoost model\n    xgb_y_pred = xgb_model.predict(X_test.reshape(-1, 4096))\n\n    # Combine the predictions from both models\n    y_pred = np.argmax(cnn_y_pred, axis=1) + xgb_y_pred\n    \n    # Convert predicted labels back to original labels using label encoder\n    y_pred_labels = label_encoder.inverse_transform(y_pred)\n\n    # Print the accuracy score\n    accuracy = accuracy_score(y_test, y_pred_labels)\n    print('Test Accuracy:', accuracy)\n    model.save('/kaggle/working/gait_classification_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-29T14:37:40.858520Z","iopub.execute_input":"2023-04-29T14:37:40.859556Z","iopub.status.idle":"2023-04-29T15:07:46.772540Z","shell.execute_reply.started":"2023-04-29T14:37:40.859510Z","shell.execute_reply":"2023-04-29T15:07:46.771117Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"D0429 14:38:12.850430636      14 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD0429 14:38:12.850477745      14 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD0429 14:38:12.850482151      14 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD0429 14:38:12.850485508      14 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD0429 14:38:12.850488432      14 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD0429 14:38:12.850491515      14 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD0429 14:38:12.850494572      14 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD0429 14:38:12.850497488      14 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD0429 14:38:12.850500293      14 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD0429 14:38:12.850503061      14 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD0429 14:38:12.850514108      14 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD0429 14:38:12.850516874      14 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD0429 14:38:12.850519674      14 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD0429 14:38:12.850522526      14 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI0429 14:38:12.850740560      14 ev_epoll1_linux.cc:122]               grpc epoll fd: 63\nD0429 14:38:12.857473367      14 ev_posix.cc:144]                      Using polling engine: epoll1\nD0429 14:38:12.857500100      14 dns_resolver_ares.cc:822]             Using ares dns resolver\nD0429 14:38:12.857980941      14 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0429 14:38:12.857989597      14 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0429 14:38:12.857995444      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0429 14:38:12.857998362      14 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0429 14:38:12.858001244      14 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0429 14:38:12.858004192      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD0429 14:38:12.858010082      14 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0429 14:38:12.858024594      14 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0429 14:38:12.858049743      14 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0429 14:38:12.858064202      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0429 14:38:12.858067572      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0429 14:38:12.858070589      14 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0429 14:38:12.858074198      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD0429 14:38:12.858077445      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0429 14:38:12.858080565      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0429 14:38:12.858084627      14 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI0429 14:38:12.860238123      14 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI0429 14:38:12.892701811     266 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0429 14:38:12.910101315      14 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2023-04-29T14:38:12.910082925+00:00\", grpc_status:2}\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 1s 0us/step\nEpoch 1/250\n","output_type":"stream"},{"name":"stderr","text":"2023-04-29 14:39:18.579925: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-04-29 14:39:18.916243: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"313/313 [==============================] - ETA: 0s - loss: 4.7215 - accuracy: 0.0155","output_type":"stream"},{"name":"stderr","text":"2023-04-29 14:39:36.059506: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-04-29 14:39:36.336440: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"313/313 [==============================] - 32s 65ms/step - loss: 4.7215 - accuracy: 0.0155 - val_loss: 4.5747 - val_accuracy: 0.0336\nEpoch 2/250\n313/313 [==============================] - 7s 21ms/step - loss: 4.5125 - accuracy: 0.0376 - val_loss: 4.3510 - val_accuracy: 0.0748\nEpoch 3/250\n313/313 [==============================] - 7s 21ms/step - loss: 4.3284 - accuracy: 0.0629 - val_loss: 4.1630 - val_accuracy: 0.1104\nEpoch 4/250\n313/313 [==============================] - 7s 21ms/step - loss: 4.1518 - accuracy: 0.0919 - val_loss: 3.9798 - val_accuracy: 0.1269\nEpoch 5/250\n313/313 [==============================] - 7s 21ms/step - loss: 4.0075 - accuracy: 0.1104 - val_loss: 3.8591 - val_accuracy: 0.1697\nEpoch 6/250\n313/313 [==============================] - 7s 21ms/step - loss: 3.8679 - accuracy: 0.1302 - val_loss: 3.7380 - val_accuracy: 0.1837\nEpoch 7/250\n313/313 [==============================] - 7s 22ms/step - loss: 3.7480 - accuracy: 0.1509 - val_loss: 3.6362 - val_accuracy: 0.2025\nEpoch 8/250\n313/313 [==============================] - 7s 21ms/step - loss: 3.6283 - accuracy: 0.1713 - val_loss: 3.5163 - val_accuracy: 0.2305\nEpoch 9/250\n313/313 [==============================] - 7s 21ms/step - loss: 3.5290 - accuracy: 0.1938 - val_loss: 3.4464 - val_accuracy: 0.2417\nEpoch 10/250\n313/313 [==============================] - 7s 21ms/step - loss: 3.4329 - accuracy: 0.2052 - val_loss: 3.3549 - val_accuracy: 0.2537\nEpoch 11/250\n313/313 [==============================] - 7s 21ms/step - loss: 3.3428 - accuracy: 0.2210 - val_loss: 3.2626 - val_accuracy: 0.2789\nEpoch 12/250\n313/313 [==============================] - 7s 21ms/step - loss: 3.2620 - accuracy: 0.2342 - val_loss: 3.2150 - val_accuracy: 0.2861\nEpoch 13/250\n313/313 [==============================] - 7s 21ms/step - loss: 3.1717 - accuracy: 0.2611 - val_loss: 3.1262 - val_accuracy: 0.3085\nEpoch 14/250\n313/313 [==============================] - 7s 21ms/step - loss: 3.1042 - accuracy: 0.2650 - val_loss: 3.0642 - val_accuracy: 0.3065\nEpoch 15/250\n313/313 [==============================] - 7s 21ms/step - loss: 3.0304 - accuracy: 0.2817 - val_loss: 2.9876 - val_accuracy: 0.3389\nEpoch 16/250\n313/313 [==============================] - 7s 21ms/step - loss: 2.9725 - accuracy: 0.2960 - val_loss: 2.9500 - val_accuracy: 0.3453\nEpoch 17/250\n313/313 [==============================] - 7s 21ms/step - loss: 2.8970 - accuracy: 0.3111 - val_loss: 2.8820 - val_accuracy: 0.3577\nEpoch 18/250\n313/313 [==============================] - 7s 21ms/step - loss: 2.8262 - accuracy: 0.3223 - val_loss: 2.8358 - val_accuracy: 0.3770\nEpoch 19/250\n313/313 [==============================] - 7s 21ms/step - loss: 2.7727 - accuracy: 0.3393 - val_loss: 2.7756 - val_accuracy: 0.3858\nEpoch 20/250\n313/313 [==============================] - 7s 21ms/step - loss: 2.7295 - accuracy: 0.3451 - val_loss: 2.7469 - val_accuracy: 0.3858\nEpoch 21/250\n313/313 [==============================] - 7s 21ms/step - loss: 2.6396 - accuracy: 0.3631 - val_loss: 2.6889 - val_accuracy: 0.4014\nEpoch 22/250\n313/313 [==============================] - 7s 21ms/step - loss: 2.6011 - accuracy: 0.3729 - val_loss: 2.6408 - val_accuracy: 0.4130\nEpoch 23/250\n313/313 [==============================] - 6s 21ms/step - loss: 2.5422 - accuracy: 0.3923 - val_loss: 2.6110 - val_accuracy: 0.4126\nEpoch 24/250\n313/313 [==============================] - 6s 21ms/step - loss: 2.5118 - accuracy: 0.3961 - val_loss: 2.5579 - val_accuracy: 0.4278\nEpoch 25/250\n313/313 [==============================] - 6s 21ms/step - loss: 2.4687 - accuracy: 0.4062 - val_loss: 2.5271 - val_accuracy: 0.4378\nEpoch 26/250\n313/313 [==============================] - 6s 21ms/step - loss: 2.4226 - accuracy: 0.4148 - val_loss: 2.4932 - val_accuracy: 0.4438\nEpoch 27/250\n313/313 [==============================] - 6s 21ms/step - loss: 2.3646 - accuracy: 0.4301 - val_loss: 2.4497 - val_accuracy: 0.4566\nEpoch 28/250\n313/313 [==============================] - 6s 21ms/step - loss: 2.3224 - accuracy: 0.4437 - val_loss: 2.3996 - val_accuracy: 0.4618\nEpoch 29/250\n313/313 [==============================] - 6s 21ms/step - loss: 2.2684 - accuracy: 0.4493 - val_loss: 2.3851 - val_accuracy: 0.4702\nEpoch 30/250\n313/313 [==============================] - 6s 21ms/step - loss: 2.2411 - accuracy: 0.4532 - val_loss: 2.3571 - val_accuracy: 0.4714\nEpoch 31/250\n313/313 [==============================] - 6s 21ms/step - loss: 2.1927 - accuracy: 0.4605 - val_loss: 2.3193 - val_accuracy: 0.4786\nEpoch 32/250\n313/313 [==============================] - 7s 21ms/step - loss: 2.1621 - accuracy: 0.4797 - val_loss: 2.2885 - val_accuracy: 0.4730\nEpoch 33/250\n313/313 [==============================] - 7s 21ms/step - loss: 2.1180 - accuracy: 0.4839 - val_loss: 2.2688 - val_accuracy: 0.4854\nEpoch 34/250\n313/313 [==============================] - 7s 21ms/step - loss: 2.0862 - accuracy: 0.4905 - val_loss: 2.2388 - val_accuracy: 0.4898\nEpoch 35/250\n313/313 [==============================] - 7s 21ms/step - loss: 2.0458 - accuracy: 0.5007 - val_loss: 2.2026 - val_accuracy: 0.5070\nEpoch 36/250\n313/313 [==============================] - 7s 23ms/step - loss: 2.0092 - accuracy: 0.5030 - val_loss: 2.1850 - val_accuracy: 0.5090\nEpoch 37/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.9939 - accuracy: 0.5097 - val_loss: 2.1610 - val_accuracy: 0.5130\nEpoch 38/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.9520 - accuracy: 0.5169 - val_loss: 2.1277 - val_accuracy: 0.5206\nEpoch 39/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.9141 - accuracy: 0.5381 - val_loss: 2.0959 - val_accuracy: 0.5286\nEpoch 40/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.8865 - accuracy: 0.5318 - val_loss: 2.1000 - val_accuracy: 0.5210\nEpoch 41/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.8625 - accuracy: 0.5408 - val_loss: 2.0693 - val_accuracy: 0.5238\nEpoch 42/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.8211 - accuracy: 0.5534 - val_loss: 2.0447 - val_accuracy: 0.5294\nEpoch 43/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.8054 - accuracy: 0.5586 - val_loss: 2.0226 - val_accuracy: 0.5370\nEpoch 44/250\n313/313 [==============================] - 6s 21ms/step - loss: 1.7717 - accuracy: 0.5627 - val_loss: 1.9950 - val_accuracy: 0.5446\nEpoch 45/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.7426 - accuracy: 0.5664 - val_loss: 1.9882 - val_accuracy: 0.5394\nEpoch 46/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.7156 - accuracy: 0.5745 - val_loss: 1.9660 - val_accuracy: 0.5458\nEpoch 47/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.7023 - accuracy: 0.5763 - val_loss: 1.9414 - val_accuracy: 0.5478\nEpoch 48/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.6672 - accuracy: 0.5805 - val_loss: 1.9375 - val_accuracy: 0.5534\nEpoch 49/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.6519 - accuracy: 0.5914 - val_loss: 1.9018 - val_accuracy: 0.5554\nEpoch 50/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.6289 - accuracy: 0.5901 - val_loss: 1.8997 - val_accuracy: 0.5554\nEpoch 51/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.5876 - accuracy: 0.6021 - val_loss: 1.8754 - val_accuracy: 0.5666\nEpoch 52/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.5673 - accuracy: 0.6060 - val_loss: 1.8501 - val_accuracy: 0.5658\nEpoch 53/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.5595 - accuracy: 0.6103 - val_loss: 1.8521 - val_accuracy: 0.5666\nEpoch 54/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.5240 - accuracy: 0.6223 - val_loss: 1.8169 - val_accuracy: 0.5682\nEpoch 55/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.5131 - accuracy: 0.6229 - val_loss: 1.8197 - val_accuracy: 0.5706\nEpoch 56/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.4948 - accuracy: 0.6242 - val_loss: 1.8005 - val_accuracy: 0.5718\nEpoch 57/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.4568 - accuracy: 0.6406 - val_loss: 1.7821 - val_accuracy: 0.5794\nEpoch 58/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.4311 - accuracy: 0.6432 - val_loss: 1.7589 - val_accuracy: 0.5878\nEpoch 59/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.4203 - accuracy: 0.6406 - val_loss: 1.7540 - val_accuracy: 0.5806\nEpoch 60/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.4001 - accuracy: 0.6517 - val_loss: 1.7491 - val_accuracy: 0.5822\nEpoch 61/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.3700 - accuracy: 0.6544 - val_loss: 1.7399 - val_accuracy: 0.5878\nEpoch 62/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.3709 - accuracy: 0.6540 - val_loss: 1.7215 - val_accuracy: 0.5862\nEpoch 63/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.3472 - accuracy: 0.6690 - val_loss: 1.7011 - val_accuracy: 0.5982\nEpoch 64/250\n313/313 [==============================] - 7s 23ms/step - loss: 1.3288 - accuracy: 0.6610 - val_loss: 1.7049 - val_accuracy: 0.5950\nEpoch 65/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.3092 - accuracy: 0.6697 - val_loss: 1.6959 - val_accuracy: 0.5994\nEpoch 66/250\n313/313 [==============================] - 7s 22ms/step - loss: 1.2982 - accuracy: 0.6765 - val_loss: 1.6714 - val_accuracy: 0.6042\nEpoch 67/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.2674 - accuracy: 0.6766 - val_loss: 1.6614 - val_accuracy: 0.6062\nEpoch 68/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.2645 - accuracy: 0.6790 - val_loss: 1.6519 - val_accuracy: 0.6014\nEpoch 69/250\n313/313 [==============================] - 7s 22ms/step - loss: 1.2391 - accuracy: 0.6862 - val_loss: 1.6213 - val_accuracy: 0.6114\nEpoch 70/250\n313/313 [==============================] - 7s 22ms/step - loss: 1.2274 - accuracy: 0.6895 - val_loss: 1.6463 - val_accuracy: 0.6054\nEpoch 71/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.2073 - accuracy: 0.6903 - val_loss: 1.6216 - val_accuracy: 0.6138\nEpoch 72/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.1900 - accuracy: 0.7030 - val_loss: 1.6127 - val_accuracy: 0.6122\nEpoch 73/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.1906 - accuracy: 0.6989 - val_loss: 1.5959 - val_accuracy: 0.6150\nEpoch 74/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.1685 - accuracy: 0.7095 - val_loss: 1.5976 - val_accuracy: 0.6122\nEpoch 75/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.1354 - accuracy: 0.7150 - val_loss: 1.5840 - val_accuracy: 0.6118\nEpoch 76/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.1270 - accuracy: 0.7178 - val_loss: 1.5825 - val_accuracy: 0.6166\nEpoch 77/250\n313/313 [==============================] - 7s 22ms/step - loss: 1.1186 - accuracy: 0.7194 - val_loss: 1.5661 - val_accuracy: 0.6182\nEpoch 78/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.0945 - accuracy: 0.7212 - val_loss: 1.5832 - val_accuracy: 0.6206\nEpoch 79/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.0930 - accuracy: 0.7253 - val_loss: 1.5680 - val_accuracy: 0.6162\nEpoch 80/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.0600 - accuracy: 0.7309 - val_loss: 1.5509 - val_accuracy: 0.6283\nEpoch 81/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.0734 - accuracy: 0.7256 - val_loss: 1.5356 - val_accuracy: 0.6299\nEpoch 82/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.0514 - accuracy: 0.7354 - val_loss: 1.5282 - val_accuracy: 0.6271\nEpoch 83/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.0267 - accuracy: 0.7390 - val_loss: 1.5359 - val_accuracy: 0.6194\nEpoch 84/250\n313/313 [==============================] - 7s 21ms/step - loss: 1.0289 - accuracy: 0.7354 - val_loss: 1.4995 - val_accuracy: 0.6331\nEpoch 85/250\n313/313 [==============================] - 6s 21ms/step - loss: 1.0064 - accuracy: 0.7419 - val_loss: 1.5260 - val_accuracy: 0.6230\nEpoch 86/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.9890 - accuracy: 0.7483 - val_loss: 1.5047 - val_accuracy: 0.6383\nEpoch 87/250\n313/313 [==============================] - 6s 21ms/step - loss: 0.9790 - accuracy: 0.7500 - val_loss: 1.4820 - val_accuracy: 0.6387\nEpoch 88/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.9694 - accuracy: 0.7494 - val_loss: 1.4905 - val_accuracy: 0.6339\nEpoch 89/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.9611 - accuracy: 0.7534 - val_loss: 1.4922 - val_accuracy: 0.6291\nEpoch 90/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.9381 - accuracy: 0.7638 - val_loss: 1.4737 - val_accuracy: 0.6359\nEpoch 91/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.9412 - accuracy: 0.7638 - val_loss: 1.4813 - val_accuracy: 0.6363\nEpoch 92/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.9265 - accuracy: 0.7640 - val_loss: 1.4695 - val_accuracy: 0.6411\nEpoch 93/250\n313/313 [==============================] - 7s 23ms/step - loss: 0.9136 - accuracy: 0.7667 - val_loss: 1.4526 - val_accuracy: 0.6503\nEpoch 94/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.9029 - accuracy: 0.7723 - val_loss: 1.4432 - val_accuracy: 0.6511\nEpoch 95/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.8782 - accuracy: 0.7775 - val_loss: 1.4447 - val_accuracy: 0.6431\nEpoch 96/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.8884 - accuracy: 0.7715 - val_loss: 1.4265 - val_accuracy: 0.6555\nEpoch 97/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.8642 - accuracy: 0.7809 - val_loss: 1.4261 - val_accuracy: 0.6511\nEpoch 98/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.8522 - accuracy: 0.7856 - val_loss: 1.4328 - val_accuracy: 0.6543\nEpoch 99/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.8580 - accuracy: 0.7831 - val_loss: 1.4580 - val_accuracy: 0.6303\nEpoch 100/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.8452 - accuracy: 0.7864 - val_loss: 1.4218 - val_accuracy: 0.6447\nEpoch 101/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.8247 - accuracy: 0.7897 - val_loss: 1.4328 - val_accuracy: 0.6447\nEpoch 102/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.8171 - accuracy: 0.7935 - val_loss: 1.4119 - val_accuracy: 0.6539\nEpoch 103/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.8079 - accuracy: 0.7917 - val_loss: 1.4131 - val_accuracy: 0.6463\nEpoch 104/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7947 - accuracy: 0.8012 - val_loss: 1.4145 - val_accuracy: 0.6459\nEpoch 105/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7988 - accuracy: 0.7970 - val_loss: 1.4045 - val_accuracy: 0.6527\nEpoch 106/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7768 - accuracy: 0.8014 - val_loss: 1.3906 - val_accuracy: 0.6511\nEpoch 107/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7702 - accuracy: 0.8018 - val_loss: 1.4045 - val_accuracy: 0.6559\nEpoch 108/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7664 - accuracy: 0.8015 - val_loss: 1.3935 - val_accuracy: 0.6515\nEpoch 109/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7526 - accuracy: 0.8135 - val_loss: 1.3765 - val_accuracy: 0.6595\nEpoch 110/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.7454 - accuracy: 0.8117 - val_loss: 1.3886 - val_accuracy: 0.6527\nEpoch 111/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7385 - accuracy: 0.8128 - val_loss: 1.3837 - val_accuracy: 0.6607\nEpoch 112/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7383 - accuracy: 0.8090 - val_loss: 1.3866 - val_accuracy: 0.6567\nEpoch 113/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7227 - accuracy: 0.8146 - val_loss: 1.3729 - val_accuracy: 0.6571\nEpoch 114/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7118 - accuracy: 0.8144 - val_loss: 1.3620 - val_accuracy: 0.6659\nEpoch 115/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7042 - accuracy: 0.8184 - val_loss: 1.3562 - val_accuracy: 0.6675\nEpoch 116/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.6873 - accuracy: 0.8269 - val_loss: 1.3699 - val_accuracy: 0.6531\nEpoch 117/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.7018 - accuracy: 0.8208 - val_loss: 1.3643 - val_accuracy: 0.6623\nEpoch 118/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.6822 - accuracy: 0.8243 - val_loss: 1.3671 - val_accuracy: 0.6639\nEpoch 119/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.6736 - accuracy: 0.8281 - val_loss: 1.3462 - val_accuracy: 0.6707\nEpoch 120/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.6731 - accuracy: 0.8235 - val_loss: 1.3483 - val_accuracy: 0.6643\nEpoch 121/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.6651 - accuracy: 0.8280 - val_loss: 1.3451 - val_accuracy: 0.6695\nEpoch 122/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.6520 - accuracy: 0.8317 - val_loss: 1.3380 - val_accuracy: 0.6631\nEpoch 123/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.6468 - accuracy: 0.8336 - val_loss: 1.3434 - val_accuracy: 0.6631\nEpoch 124/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.6472 - accuracy: 0.8328 - val_loss: 1.3415 - val_accuracy: 0.6599\nEpoch 125/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.6333 - accuracy: 0.8333 - val_loss: 1.3359 - val_accuracy: 0.6611\nEpoch 126/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.6249 - accuracy: 0.8412 - val_loss: 1.3368 - val_accuracy: 0.6619\nEpoch 127/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.6191 - accuracy: 0.8420 - val_loss: 1.3188 - val_accuracy: 0.6731\nEpoch 128/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.6114 - accuracy: 0.8464 - val_loss: 1.3498 - val_accuracy: 0.6675\nEpoch 129/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5986 - accuracy: 0.8481 - val_loss: 1.3368 - val_accuracy: 0.6559\nEpoch 130/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.5946 - accuracy: 0.8473 - val_loss: 1.3175 - val_accuracy: 0.6755\nEpoch 131/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.6035 - accuracy: 0.8467 - val_loss: 1.3075 - val_accuracy: 0.6711\nEpoch 132/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5831 - accuracy: 0.8528 - val_loss: 1.3235 - val_accuracy: 0.6635\nEpoch 133/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5780 - accuracy: 0.8562 - val_loss: 1.3259 - val_accuracy: 0.6631\nEpoch 134/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5835 - accuracy: 0.8498 - val_loss: 1.3097 - val_accuracy: 0.6703\nEpoch 135/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5770 - accuracy: 0.8529 - val_loss: 1.3172 - val_accuracy: 0.6679\nEpoch 136/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5603 - accuracy: 0.8571 - val_loss: 1.3174 - val_accuracy: 0.6707\nEpoch 137/250\n313/313 [==============================] - 6s 21ms/step - loss: 0.5603 - accuracy: 0.8581 - val_loss: 1.3065 - val_accuracy: 0.6719\nEpoch 138/250\n313/313 [==============================] - 6s 21ms/step - loss: 0.5407 - accuracy: 0.8664 - val_loss: 1.3187 - val_accuracy: 0.6623\nEpoch 139/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5497 - accuracy: 0.8586 - val_loss: 1.3031 - val_accuracy: 0.6763\nEpoch 140/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5386 - accuracy: 0.8634 - val_loss: 1.3010 - val_accuracy: 0.6751\nEpoch 141/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5397 - accuracy: 0.8622 - val_loss: 1.3001 - val_accuracy: 0.6715\nEpoch 142/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5263 - accuracy: 0.8684 - val_loss: 1.2927 - val_accuracy: 0.6767\nEpoch 143/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5266 - accuracy: 0.8646 - val_loss: 1.2976 - val_accuracy: 0.6779\nEpoch 144/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5154 - accuracy: 0.8689 - val_loss: 1.2997 - val_accuracy: 0.6683\nEpoch 145/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5024 - accuracy: 0.8732 - val_loss: 1.2814 - val_accuracy: 0.6727\nEpoch 146/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5070 - accuracy: 0.8678 - val_loss: 1.2892 - val_accuracy: 0.6743\nEpoch 147/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.5078 - accuracy: 0.8721 - val_loss: 1.3017 - val_accuracy: 0.6747\nEpoch 148/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4965 - accuracy: 0.8695 - val_loss: 1.2794 - val_accuracy: 0.6791\nEpoch 149/250\n313/313 [==============================] - 7s 23ms/step - loss: 0.4834 - accuracy: 0.8763 - val_loss: 1.2720 - val_accuracy: 0.6799\nEpoch 150/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.4868 - accuracy: 0.8784 - val_loss: 1.2766 - val_accuracy: 0.6811\nEpoch 151/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.4894 - accuracy: 0.8728 - val_loss: 1.2767 - val_accuracy: 0.6795\nEpoch 152/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4845 - accuracy: 0.8763 - val_loss: 1.2795 - val_accuracy: 0.6731\nEpoch 153/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4771 - accuracy: 0.8817 - val_loss: 1.2741 - val_accuracy: 0.6803\nEpoch 154/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4579 - accuracy: 0.8818 - val_loss: 1.2769 - val_accuracy: 0.6803\nEpoch 155/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4558 - accuracy: 0.8887 - val_loss: 1.2831 - val_accuracy: 0.6759\nEpoch 156/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.4625 - accuracy: 0.8801 - val_loss: 1.2896 - val_accuracy: 0.6763\nEpoch 157/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.4518 - accuracy: 0.8823 - val_loss: 1.2716 - val_accuracy: 0.6819\nEpoch 158/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4512 - accuracy: 0.8864 - val_loss: 1.2844 - val_accuracy: 0.6779\nEpoch 159/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4460 - accuracy: 0.8855 - val_loss: 1.2800 - val_accuracy: 0.6787\nEpoch 160/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4433 - accuracy: 0.8869 - val_loss: 1.2706 - val_accuracy: 0.6763\nEpoch 161/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4311 - accuracy: 0.8907 - val_loss: 1.2846 - val_accuracy: 0.6743\nEpoch 162/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4217 - accuracy: 0.8957 - val_loss: 1.2798 - val_accuracy: 0.6819\nEpoch 163/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4299 - accuracy: 0.8890 - val_loss: 1.2679 - val_accuracy: 0.6775\nEpoch 164/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4171 - accuracy: 0.8954 - val_loss: 1.2501 - val_accuracy: 0.6871\nEpoch 165/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4210 - accuracy: 0.8927 - val_loss: 1.2542 - val_accuracy: 0.6839\nEpoch 166/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4153 - accuracy: 0.8959 - val_loss: 1.2690 - val_accuracy: 0.6775\nEpoch 167/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4090 - accuracy: 0.8997 - val_loss: 1.2797 - val_accuracy: 0.6807\nEpoch 168/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.4062 - accuracy: 0.8985 - val_loss: 1.2674 - val_accuracy: 0.6831\nEpoch 169/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3900 - accuracy: 0.9028 - val_loss: 1.2716 - val_accuracy: 0.6779\nEpoch 170/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3905 - accuracy: 0.9032 - val_loss: 1.2748 - val_accuracy: 0.6795\nEpoch 171/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3992 - accuracy: 0.8994 - val_loss: 1.2762 - val_accuracy: 0.6831\nEpoch 172/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3919 - accuracy: 0.9027 - val_loss: 1.2634 - val_accuracy: 0.6883\nEpoch 173/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3831 - accuracy: 0.9050 - val_loss: 1.2642 - val_accuracy: 0.6819\nEpoch 174/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3859 - accuracy: 0.9063 - val_loss: 1.2527 - val_accuracy: 0.6851\nEpoch 175/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3793 - accuracy: 0.9059 - val_loss: 1.2489 - val_accuracy: 0.6867\nEpoch 176/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3872 - accuracy: 0.9004 - val_loss: 1.2733 - val_accuracy: 0.6759\nEpoch 177/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3750 - accuracy: 0.9051 - val_loss: 1.2541 - val_accuracy: 0.6887\nEpoch 178/250\n313/313 [==============================] - 7s 23ms/step - loss: 0.3756 - accuracy: 0.9081 - val_loss: 1.2665 - val_accuracy: 0.6879\nEpoch 179/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.3667 - accuracy: 0.9079 - val_loss: 1.2442 - val_accuracy: 0.6903\nEpoch 180/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.3650 - accuracy: 0.9079 - val_loss: 1.2552 - val_accuracy: 0.6831\nEpoch 181/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3488 - accuracy: 0.9116 - val_loss: 1.2685 - val_accuracy: 0.6783\nEpoch 182/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3510 - accuracy: 0.9119 - val_loss: 1.2773 - val_accuracy: 0.6867\nEpoch 183/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3529 - accuracy: 0.9097 - val_loss: 1.2440 - val_accuracy: 0.6903\nEpoch 184/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3508 - accuracy: 0.9139 - val_loss: 1.2624 - val_accuracy: 0.6835\nEpoch 185/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3473 - accuracy: 0.9131 - val_loss: 1.2586 - val_accuracy: 0.6827\nEpoch 186/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3386 - accuracy: 0.9153 - val_loss: 1.2671 - val_accuracy: 0.6871\nEpoch 187/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3345 - accuracy: 0.9159 - val_loss: 1.2715 - val_accuracy: 0.6819\nEpoch 188/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3331 - accuracy: 0.9177 - val_loss: 1.2608 - val_accuracy: 0.6863\nEpoch 189/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3403 - accuracy: 0.9126 - val_loss: 1.2626 - val_accuracy: 0.6887\nEpoch 190/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3285 - accuracy: 0.9162 - val_loss: 1.2687 - val_accuracy: 0.6895\nEpoch 191/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3207 - accuracy: 0.9207 - val_loss: 1.2664 - val_accuracy: 0.6883\nEpoch 192/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3227 - accuracy: 0.9177 - val_loss: 1.2601 - val_accuracy: 0.6859\nEpoch 193/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3307 - accuracy: 0.9161 - val_loss: 1.2741 - val_accuracy: 0.6815\nEpoch 194/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3277 - accuracy: 0.9161 - val_loss: 1.2467 - val_accuracy: 0.6931\nEpoch 195/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3194 - accuracy: 0.9226 - val_loss: 1.2694 - val_accuracy: 0.6855\nEpoch 196/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3186 - accuracy: 0.9184 - val_loss: 1.2640 - val_accuracy: 0.6907\nEpoch 197/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3234 - accuracy: 0.9209 - val_loss: 1.2732 - val_accuracy: 0.6787\nEpoch 198/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3094 - accuracy: 0.9215 - val_loss: 1.2682 - val_accuracy: 0.6875\nEpoch 199/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3040 - accuracy: 0.9262 - val_loss: 1.2669 - val_accuracy: 0.6855\nEpoch 200/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3024 - accuracy: 0.9270 - val_loss: 1.2657 - val_accuracy: 0.6799\nEpoch 201/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.3080 - accuracy: 0.9218 - val_loss: 1.2624 - val_accuracy: 0.6807\nEpoch 202/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2947 - accuracy: 0.9270 - val_loss: 1.2695 - val_accuracy: 0.6875\nEpoch 203/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2979 - accuracy: 0.9249 - val_loss: 1.2588 - val_accuracy: 0.6867\nEpoch 204/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2898 - accuracy: 0.9288 - val_loss: 1.2713 - val_accuracy: 0.6935\nEpoch 205/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2890 - accuracy: 0.9248 - val_loss: 1.2749 - val_accuracy: 0.6851\nEpoch 206/250\n313/313 [==============================] - 7s 23ms/step - loss: 0.2955 - accuracy: 0.9264 - val_loss: 1.2798 - val_accuracy: 0.6843\nEpoch 207/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2836 - accuracy: 0.9302 - val_loss: 1.2784 - val_accuracy: 0.6883\nEpoch 208/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2924 - accuracy: 0.9243 - val_loss: 1.2746 - val_accuracy: 0.6891\nEpoch 209/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2767 - accuracy: 0.9326 - val_loss: 1.2555 - val_accuracy: 0.6919\nEpoch 210/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2692 - accuracy: 0.9342 - val_loss: 1.2714 - val_accuracy: 0.6867\nEpoch 211/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2834 - accuracy: 0.9262 - val_loss: 1.2514 - val_accuracy: 0.6911\nEpoch 212/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2697 - accuracy: 0.9325 - val_loss: 1.2725 - val_accuracy: 0.6867\nEpoch 213/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2704 - accuracy: 0.9299 - val_loss: 1.2654 - val_accuracy: 0.6875\nEpoch 214/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2648 - accuracy: 0.9358 - val_loss: 1.2718 - val_accuracy: 0.6903\nEpoch 215/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2677 - accuracy: 0.9365 - val_loss: 1.2775 - val_accuracy: 0.6847\nEpoch 216/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2715 - accuracy: 0.9326 - val_loss: 1.2697 - val_accuracy: 0.6859\nEpoch 217/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2639 - accuracy: 0.9336 - val_loss: 1.2626 - val_accuracy: 0.6919\nEpoch 218/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2549 - accuracy: 0.9382 - val_loss: 1.2602 - val_accuracy: 0.6895\nEpoch 219/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2512 - accuracy: 0.9393 - val_loss: 1.2633 - val_accuracy: 0.6923\nEpoch 220/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2486 - accuracy: 0.9394 - val_loss: 1.2723 - val_accuracy: 0.6839\nEpoch 221/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2589 - accuracy: 0.9345 - val_loss: 1.2544 - val_accuracy: 0.6887\nEpoch 222/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2536 - accuracy: 0.9358 - val_loss: 1.2618 - val_accuracy: 0.6827\nEpoch 223/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2435 - accuracy: 0.9417 - val_loss: 1.2643 - val_accuracy: 0.6899\nEpoch 224/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2451 - accuracy: 0.9411 - val_loss: 1.2762 - val_accuracy: 0.6859\nEpoch 225/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2484 - accuracy: 0.9385 - val_loss: 1.2928 - val_accuracy: 0.6791\nEpoch 226/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2450 - accuracy: 0.9410 - val_loss: 1.2834 - val_accuracy: 0.6875\nEpoch 227/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2360 - accuracy: 0.9426 - val_loss: 1.2583 - val_accuracy: 0.6923\nEpoch 228/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2488 - accuracy: 0.9368 - val_loss: 1.2731 - val_accuracy: 0.6915\nEpoch 229/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2369 - accuracy: 0.9412 - val_loss: 1.2694 - val_accuracy: 0.6851\nEpoch 230/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2431 - accuracy: 0.9397 - val_loss: 1.2584 - val_accuracy: 0.6907\nEpoch 231/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2370 - accuracy: 0.9430 - val_loss: 1.2623 - val_accuracy: 0.6927\nEpoch 232/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2318 - accuracy: 0.9415 - val_loss: 1.2634 - val_accuracy: 0.6943\nEpoch 233/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2299 - accuracy: 0.9435 - val_loss: 1.2701 - val_accuracy: 0.6915\nEpoch 234/250\n313/313 [==============================] - 7s 23ms/step - loss: 0.2328 - accuracy: 0.9435 - val_loss: 1.2720 - val_accuracy: 0.6859\nEpoch 235/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2300 - accuracy: 0.9439 - val_loss: 1.3031 - val_accuracy: 0.6843\nEpoch 236/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2223 - accuracy: 0.9461 - val_loss: 1.2802 - val_accuracy: 0.6879\nEpoch 237/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2261 - accuracy: 0.9452 - val_loss: 1.2848 - val_accuracy: 0.6899\nEpoch 238/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2299 - accuracy: 0.9423 - val_loss: 1.2654 - val_accuracy: 0.6923\nEpoch 239/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2207 - accuracy: 0.9421 - val_loss: 1.2823 - val_accuracy: 0.6823\nEpoch 240/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2165 - accuracy: 0.9480 - val_loss: 1.2849 - val_accuracy: 0.6931\nEpoch 241/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2187 - accuracy: 0.9449 - val_loss: 1.2947 - val_accuracy: 0.6799\nEpoch 242/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2156 - accuracy: 0.9470 - val_loss: 1.2763 - val_accuracy: 0.6947\nEpoch 243/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2128 - accuracy: 0.9480 - val_loss: 1.2921 - val_accuracy: 0.6831\nEpoch 244/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2134 - accuracy: 0.9468 - val_loss: 1.3135 - val_accuracy: 0.6891\nEpoch 245/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2236 - accuracy: 0.9440 - val_loss: 1.2804 - val_accuracy: 0.6911\nEpoch 246/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2069 - accuracy: 0.9495 - val_loss: 1.2820 - val_accuracy: 0.6899\nEpoch 247/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2171 - accuracy: 0.9451 - val_loss: 1.2729 - val_accuracy: 0.6903\nEpoch 248/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2081 - accuracy: 0.9496 - val_loss: 1.2861 - val_accuracy: 0.6855\nEpoch 249/250\n313/313 [==============================] - 7s 22ms/step - loss: 0.2064 - accuracy: 0.9507 - val_loss: 1.2784 - val_accuracy: 0.6935\nEpoch 250/250\n313/313 [==============================] - 7s 21ms/step - loss: 0.2007 - accuracy: 0.9533 - val_loss: 1.2909 - val_accuracy: 0.6907\n","output_type":"stream"},{"name":"stderr","text":"2023-04-29 15:07:37.414763: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-04-29 15:07:37.660842: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"79/79 [==============================] - 10s 51ms/step\nTest Accuracy: 0.9324129651860744\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n# Define TPU strategy\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n\n    # Load data\n    df = pd.read_csv('/kaggle/input/gait-analysis/gait_features_cnn_trained.csv')\n    X = df.drop(['label'], axis=1).values\n    y = df['label'].values\n\n    # Encode the labels\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Reshape data for use with ResNet50\n    X_train = X_train.reshape(-1, 64, 64)\n    X_test = X_test.reshape(-1, 64, 64)\n    X_train = np.repeat(X_train[..., np.newaxis], 3, -1)\n    X_test = np.repeat(X_test[..., np.newaxis], 3, -1)\n\n    # Load ResNet50 model and freeze convolutional layers\n    resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n    resnet50.trainable = False\n\n    # Create a CNN model\n    model = Sequential()\n    model.add(resnet50)\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n\n    # Compile the model\n    optimizer = Adam(learning_rate=0.0001)\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    # Train the model\n    model.fit(X_train, y_train, epochs=250, validation_data=(X_test, y_test))\n\n    # Perform predictions using the model\n    y_pred = model.predict(X_test)\n    y_pred = np.argmax(y_pred, axis=1)\n\n    # Convert predicted labels back to original labels using label encoder\n    y_pred_labels = label_encoder.inverse_transform(y_pred)\n\n    # Print the accuracy score\n    accuracy = accuracy_score(y_test, y_pred)\n    print('Test Accuracy:', accuracy) \n    # Save the model\n    model.save('/kaggle/working/gait_classification_model.h5')\n\n","metadata":{},"execution_count":null,"outputs":[]}]}